# -*- coding: utf-8 -*-
"""MarketBasketMartinaNavarria.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/115euRZjKVKSVGpA0hcRO298UxnwHugEP

Dataset link:https://www.kaggle.com/datasets/zdenzyurt/rfm-dataset

# Market Basket Analysis

Market basket analysis is a technique used by businesses, especially retailers, to understand how customers purchase together. It analyzes large sets of customer transaction data to identify patterns of co-occurrence between products. By understanding these patterns, businesses can recommend related products to customers (like milk with bread), potentially leading to more purchases.

This dataset contains information about retail transactions. It includes 522,065 rows with 7 attributes describing each purchase.

Transactions: Each row represents a single transaction identified by a unique BillNo (6-digit number).
Products: The Itemname (text) specifies the product purchased, and the Quantity (number) indicates how many were bought.
Customers: CustomerID (5-digit number) helps identify the customer, and Country (text) specifies their location.
Sales Details: The purchase Date (date and time) is recorded along with the Price (number) paid for each item.
"""

from google.colab import drive
drive.mount("/content/gdrive")

#Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules

df_raw = pd.read_csv('/content/gdrive/MyDrive/WebSocial-24/OnlineRetail.csv', encoding='latin1')

df_raw

df_raw.info()

df_raw.isna().sum() #check for null values

del df_raw['CustomerID']

negativeorNull = df_raw.loc[df_raw['Quantity']<=0]
print('Count of Null or negative quantity: ', len(negativeorNull))

df_raw = df_raw.loc[df_raw['Quantity']>0] #to keep only rows where the value in the "Quantity" column is greater than 0

negativeorNull = df_raw.loc[df_raw['UnitPrice']<=0]
print('Count of Null or negative quantity: ', len(negativeorNull))

df_raw = df_raw.loc[df_raw['UnitPrice']>0] #to keep only rows where the value in the "UnitPrice" column is greater than 0

df_raw.info()

print(f'Number of unique products: {df_raw.Description.nunique()}') #Number of unique products

print(f'Start of the dataset: { df_raw.InvoiceDate.min()}') #First purchase date

print(f'End of the dataset: { df_raw.InvoiceDate.max()}') #Last purchase date

df_raw['InvoiceDate'] = pd.to_datetime(df_raw['InvoiceDate'], format='%d-%m-%Y %H:%M') #convert the date to datetime format

"""### Most popular items"""

df_agg_items = (
    df_raw
    .groupby('Description')
    .size()  # Count occurrences in each 'Description' group
    .to_frame(name='nu_records')  # Create a DataFrame with the count as 'nu_records'
    .reset_index()  # Add 'Description' as a column
    .sort_values(by='nu_records', ascending=False)  # Sort by 'nu_records' descending
)

color = plt.cm.rainbow(np.linspace(0, 1, 25))

# Get the frequency of the top 25 most popular items (extracted from the 'Description' column)
item_counts = df_raw['Description'].value_counts().head(25)
item_names = item_counts.index.to_numpy()  # Extract item descriptions as labels

# Create a bar chart with the color gradient and custom x-axis labels
plt.figure(figsize=(13, 5))  # Set figure size
plt.bar(item_names, item_counts, color=color)  # Use item descriptions as x-axis labels

# Add a title, rotate x-axis labels for readability if needed, and show grid lines
plt.title('Frequency of Most Popular Items', fontsize=20)
plt.xticks(rotation=90 if len(item_names) > 15 else 0)  # Rotate only if many labels
plt.grid()

plt.show()

df_agg_items.head(10) #Top 10 most popular items

df_agg_purchases = (
    df_raw
    .groupby('InvoiceDate')  # Group by 'Date' only
    .agg(nu_items=('Description', 'count'))  # Count items per 'Date'
    .reset_index()  # Add 'Date' as a column
    .sort_values(by='nu_items', ascending=False)  # Sort by 'nu_items' descending
)

df_agg_purchases

df_agg_purchases.describe(percentiles=[.01,.05,.1,.2,.3,.4,.5,.6,.7,.8,.90,.95,.99]).T

# Aggregate data by date
df_agg_dates = df_raw.groupby('InvoiceDate').size().reset_index(name='NumberOfPurchases')


plt.figure(figsize=(20, 12))
plt.style.use('fivethirtyeight')

# Plot the purchase dates
sns.lineplot(data=df_agg_dates, x='InvoiceDate', y='NumberOfPurchases', color='purple', linewidth=1)


# Set labels and title
plt.xlabel('Date')
plt.ylabel('Number of Purchases')
plt.title('Number of Purchases Over Time')

# Adjust layout
plt.tight_layout()

# Display the plot
plt.show()

start_date = '2011-06-01'  # Corrected start date format
end_date = '2011-06-08'    # Corrected end date format

# Filter data within the specified date range, assuming 'InvoiceDate' is the correct column
weekly_data = df_raw[(df_raw['InvoiceDate'] >= start_date) & (df_raw['InvoiceDate'] <= end_date)]

# Convert 'InvoiceDate' to datetime if it's not already
weekly_data['InvoiceDate'] = pd.to_datetime(weekly_data['InvoiceDate'])

# Extract day of the week from 'InvoiceDate'
weekly_data['DayOfWeek'] = weekly_data['InvoiceDate'].dt.day_name()

day_counts = weekly_data['DayOfWeek'].value_counts().reindex(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']).fillna(0)

sns.set(style="whitegrid")

plt.figure(figsize=(20, 6))
plt.plot(day_counts.index, day_counts.values, marker='o', linestyle='-', color='#edbbec', linewidth=2, markersize=8)


plt.title('Number of Purchases by Day of the Week', fontsize=30, weight='bold')
plt.xlabel('Day of the Week', fontsize=25)
plt.ylabel('Number of Purchases', fontsize=25)


plt.grid(visible=True, which='major', color='grey', linestyle='--', linewidth=0.5)

plt.xticks(rotation=0, fontsize=20)
plt.yticks(fontsize=20)

for i in range(len(day_counts)):
    plt.text(i, day_counts.values[i] + 0.2,
             f"{int(day_counts.values[i])}", ha='center',color='#e01ddc',  fontsize=15, weight='bold')

plt.gca().set_facecolor('#faf0f0')

plt.tight_layout()

plt.show()

start_date = '2011-07-01'  # Corrected start date format
end_date = '2011-07-08'    # Corrected end date format

# Filter data within the specified date range, assuming 'InvoiceDate' is the correct column
weekly_data = df_raw[(df_raw['InvoiceDate'] >= start_date) & (df_raw['InvoiceDate'] <= end_date)]

# Extract day of the week from 'InvoiceDate'
weekly_data['DayOfWeek'] = weekly_data['InvoiceDate'].dt.day_name()

day_counts = weekly_data['DayOfWeek'].value_counts().reindex(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']).fillna(0)

sns.set(style="whitegrid")

plt.figure(figsize=(20, 6))
plt.plot(day_counts.index, day_counts.values, marker='o', linestyle='-', color='#edbbec', linewidth=2, markersize=8)


plt.title('Number of Purchases by Day of the Week', fontsize=30, weight='bold')
plt.xlabel('Day of the Week', fontsize=25)
plt.ylabel('Number of Purchases', fontsize=25)


plt.grid(visible=True, which='major', color='grey', linestyle='--', linewidth=0.5)

plt.xticks(rotation=0, fontsize=20)
plt.yticks(fontsize=20)

for i in range(len(day_counts)):
    plt.text(i, day_counts.values[i] + 0.2,
             f"{int(day_counts.values[i])}", ha='center',color='#e01ddc',  fontsize=15, weight='bold')

plt.gca().set_facecolor('#faf0f0')

plt.tight_layout()

plt.show()

start_date = '2011-08-01'  # Corrected start date format
end_date = '2011-08-08'    # Corrected end date format

# Filter data within the specified date range, assuming 'InvoiceDate' is the correct column
weekly_data = df_raw[(df_raw['InvoiceDate'] >= start_date) & (df_raw['InvoiceDate'] <= end_date)]

# Convert 'InvoiceDate' to datetime if it's not already
weekly_data['InvoiceDate'] = pd.to_datetime(weekly_data['InvoiceDate'])

# Extract day of the week from 'InvoiceDate'
weekly_data['DayOfWeek'] = weekly_data['InvoiceDate'].dt.day_name()

day_counts = weekly_data['DayOfWeek'].value_counts().reindex(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']).fillna(0)

sns.set(style="whitegrid")

plt.figure(figsize=(20, 6))
plt.plot(day_counts.index, day_counts.values, marker='o', linestyle='-', color='#edbbec', linewidth=2, markersize=8)


plt.title('Number of Purchases by Day of the Week', fontsize=30, weight='bold')
plt.xlabel('Day of the Week', fontsize=25)
plt.ylabel('Number of Purchases', fontsize=25)


plt.grid(visible=True, which='major', color='grey', linestyle='--', linewidth=0.5)

plt.xticks(rotation=0, fontsize=20)
plt.yticks(fontsize=20)

for i in range(len(day_counts)):
    plt.text(i, day_counts.values[i] + 0.2,
             f"{int(day_counts.values[i])}", ha='center',color='#e01ddc',  fontsize=15, weight='bold')

plt.gca().set_facecolor('#faf0f0')

plt.tight_layout()

plt.show()

"""as we can see, it seems to be arecurrent even that saturday has effectively a number of sales equal to zero. This might be due to paychecks being distributed during the start or middle of the week, where we can see a constant high range in sales."""

specific_day = '2011-07-04' #random monday within the dataset
mask = df_raw['InvoiceDate'].dt.date == pd.to_datetime(specific_day).date()
date_column = 'InvoiceDate'

mask = df_raw[date_column].dt.date == pd.to_datetime(specific_day).date()
daily_data = df_raw.loc[mask]

daily_data['Hour'] = daily_data[date_column].dt.hour


hour_counts = daily_data['Hour'].value_counts().sort_index()

sns.set(style="whitegrid")

plt.figure(figsize=(12, 6))
plt.plot(hour_counts.index, hour_counts.values, marker='o', linestyle='-', color='#edbbec', linewidth=2, markersize=8)

plt.title(f'Number of Purchases by Hour on {specific_day}', fontsize=16, weight='bold')
plt.xlabel('Hour of the Day', fontsize=14)
plt.ylabel('N째 of Purchases', fontsize=14)

plt.grid(visible=True, which='major', color='gray', linestyle='--', linewidth=0.5)

plt.xticks(hour_counts.index, fontsize=12)
plt.yticks(fontsize=12)

for i in range(len(hour_counts)):
    plt.text(hour_counts.index[i], hour_counts.values[i] + 0.2,
             f"{int(hour_counts.values[i])}", ha='center', fontsize=15, color='#e01ddc')

plt.gca().set_facecolor('#faf0f0')

plt.tight_layout()

plt.show()

"""we can see that on monday the sales tend to be focused in the morning but with a spike in the middle of the afternoon."""

specific_day = '2011-07-05'
mask = df_raw['InvoiceDate'].dt.date == pd.to_datetime(specific_day).date()
date_column = 'InvoiceDate'

mask = df_raw[date_column].dt.date == pd.to_datetime(specific_day).date()
daily_data = df_raw.loc[mask]

daily_data['Hour'] = daily_data[date_column].dt.hour


hour_counts = daily_data['Hour'].value_counts().sort_index()

sns.set(style="whitegrid")

plt.figure(figsize=(12, 6))
plt.plot(hour_counts.index, hour_counts.values, marker='o', linestyle='-', color='#edbbec', linewidth=2, markersize=8)

plt.title(f'Number of Purchases by Hour on {specific_day}', fontsize=16, weight='bold')
plt.xlabel('Hour of the Day', fontsize=14)
plt.ylabel('N째 of Purchases', fontsize=14)

plt.grid(visible=True, which='major', color='gray', linestyle='--', linewidth=0.5)

plt.xticks(hour_counts.index, fontsize=12)
plt.yticks(fontsize=12)

for i in range(len(hour_counts)):
    plt.text(hour_counts.index[i], hour_counts.values[i] + 0.2,
             f"{int(hour_counts.values[i])}", ha='center', fontsize=15, color='#e01ddc')

plt.gca().set_facecolor('#faf0f0')

plt.tight_layout()

plt.show()

specific_day = '2011-07-06'
mask = df_raw['InvoiceDate'].dt.date == pd.to_datetime(specific_day).date()
date_column = 'InvoiceDate'

mask = df_raw[date_column].dt.date == pd.to_datetime(specific_day).date()
daily_data = df_raw.loc[mask]

daily_data['Hour'] = daily_data[date_column].dt.hour


hour_counts = daily_data['Hour'].value_counts().sort_index()

sns.set(style="whitegrid")

plt.figure(figsize=(12, 6))
plt.plot(hour_counts.index, hour_counts.values, marker='o', linestyle='-', color='#edbbec', linewidth=2, markersize=8)

plt.title(f'Number of Purchases by Hour on {specific_day}', fontsize=16, weight='bold')
plt.xlabel('Hour of the Day', fontsize=14)
plt.ylabel('N째 of Purchases', fontsize=14)

plt.grid(visible=True, which='major', color='gray', linestyle='--', linewidth=0.5)

plt.xticks(hour_counts.index, fontsize=12)
plt.yticks(fontsize=12)

for i in range(len(hour_counts)):
    plt.text(hour_counts.index[i], hour_counts.values[i] + 0.2,
             f"{int(hour_counts.values[i])}", ha='center', fontsize=15, color='#e01ddc')

plt.gca().set_facecolor('#faf0f0')

plt.tight_layout()

plt.show()

specific_day = '2011-07-07'
mask = df_raw['InvoiceDate'].dt.date == pd.to_datetime(specific_day).date()
date_column = 'InvoiceDate'

mask = df_raw[date_column].dt.date == pd.to_datetime(specific_day).date()
daily_data = df_raw.loc[mask]

daily_data['Hour'] = daily_data[date_column].dt.hour


hour_counts = daily_data['Hour'].value_counts().sort_index()

sns.set(style="whitegrid")

plt.figure(figsize=(12, 6))
plt.plot(hour_counts.index, hour_counts.values, marker='o', linestyle='-', color='#edbbec', linewidth=2, markersize=8)

plt.title(f'Number of Purchases by Hour on {specific_day}', fontsize=16, weight='bold')
plt.xlabel('Hour of the Day', fontsize=14)
plt.ylabel('N째 of Purchases', fontsize=14)

plt.grid(visible=True, which='major', color='gray', linestyle='--', linewidth=0.5)

plt.xticks(hour_counts.index, fontsize=12)
plt.yticks(fontsize=12)

for i in range(len(hour_counts)):
    plt.text(hour_counts.index[i], hour_counts.values[i] + 0.2,
             f"{int(hour_counts.values[i])}", ha='center', fontsize=15, color='#e01ddc')

plt.gca().set_facecolor('#faf0f0')

plt.tight_layout()

plt.show()

"""the rest of the week keeps constant the spike at 4pm, assuming this might be the time most people end their work day could be helpful to improve marketing actions.

#Data Preprocessing
In order to apply the Market Basket Analysis model the dataset we should have one row for each purhcase.
"""

df_raw.dropna(inplace=True) #drop null values

import pandas as pd

item_counts = df_raw['Description'].value_counts() #count the number of purchases for each item

top_500_items = item_counts.nlargest(500).index

filtered_df = df_raw[df_raw['Description'].isin(top_500_items)] #filter the dataset to include only the top 500 items

df = (
    filtered_df.groupby([ 'InvoiceDate'])['Description'].apply(list).reset_index() #group by date and create a list of items for each date
)
df.columns = [ 'InvoiceDate', 'Items']

df

from mlxtend.preprocessing import TransactionEncoder
transaction_encoder = TransactionEncoder()
model = transaction_encoder.fit_transform(df['Items']) #encode the items as binary values

"""one-hot encoding"""

df_transactions = pd.DataFrame(model, columns=transaction_encoder.columns_)
df_transactions.head() #display the first few rows of the encoded dataset

"""### Apriori algorithm application
for this part we are going to reduce the amount of data we work with for timing reasons.
"""

MIN_SUPPORT_APRIORI = 0.01 #minimum support for apriori algorithm
MAX_LEN_APRIORI = 2

df_apriori_frequent_pattern = apriori(df_transactions, min_support=MIN_SUPPORT_APRIORI, max_len=MAX_LEN_APRIORI, use_colnames=True)
# add a new column itemset_length
df_apriori_frequent_pattern['itemset_length'] = df_apriori_frequent_pattern['itemsets'].apply(lambda x: len(x))

df_apriori_frequent_pattern.loc[df_apriori_frequent_pattern.itemset_length > 1].sort_values('support', ascending=False)

ASSOCIATION_RULES_METRIC = "lift" #metric to use for association rules
ASSOCIATION_RULES_MIN_TRESHOLD = 1

df_rules_apriori = association_rules(df_apriori_frequent_pattern, metric=ASSOCIATION_RULES_METRIC, min_threshold=ASSOCIATION_RULES_MIN_TRESHOLD)
df_rules_apriori.head()

"""the higher lift value seems to be obtained by the rule (4 TRADITIONAL SPINNING TOPS) ->	(TRADITIONAL WOODEN CATCH CUP GAME ) and (TRADITIONAL WOODEN CATCH CUP GAME ) ->	(4 TRADITIONAL SPINNING TOPS)"""

df_rules_apriori[df_rules_apriori["antecedents"].apply(lambda x: '4 TRADITIONAL SPINNING TOPS' in x)].sort_values('lift', ascending=False).head()

"""Frequent Pattern Growth algorithm"""

MIN_SUPPORT_FPGROWTH = MIN_SUPPORT_APRIORI
MAX_LEN_FPGROWTH = MAX_LEN_APRIORI

from mlxtend.frequent_patterns import  fpgrowth #frequent pattern growth algorithm
df_fpgrowth_frequent_pattern = fpgrowth(df_transactions, min_support=MIN_SUPPORT_FPGROWTH, max_len=MAX_LEN_FPGROWTH, use_colnames=True)
# add a new column itemset_length
df_fpgrowth_frequent_pattern['itemset_length'] = df_fpgrowth_frequent_pattern['itemsets'].apply(lambda x: len(x))

df_fpgrowth_frequent_pattern.loc[df_fpgrowth_frequent_pattern.itemset_length > 1].sort_values('support', ascending=False).head(10)

df_rules_fpgrowth = association_rules(df_fpgrowth_frequent_pattern, metric=ASSOCIATION_RULES_METRIC, min_threshold=ASSOCIATION_RULES_MIN_TRESHOLD)
df_rules_fpgrowth.head(10)

"""higher lift rule is (HAND WARMER OWL DESIGN) ->	(HAND WARMER UNION JACK) followed by (HAND WARMER UNION JACK) ->	(HAND WARMER SCOTTY DOG DESIGN)"""

df_rules_apriori[df_rules_apriori["antecedents"].apply(lambda x: 'HAND WARMER OWL DESIGN' in x)].sort_values('lift', ascending=False)